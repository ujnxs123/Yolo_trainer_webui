from pathlib import Path
from PIL import Image
import streamlit as st
import config as config
import time
import os
from ultralytics import YOLO
import cv2
from PIL import Image
import tempfile

def _display_detected_frames(conf, model, st_frame, image):
    """
    Display the detected objects on a video frame using the YOLOv8 model.
    :param conf (float): Confidence threshold for object detection.
    :param model (YOLOv8): An instance of the `YOLOv8` class containing the YOLOv8 model.
    :param st_frame (Streamlit object): A Streamlit object to display the detected video.
    :param image (numpy array): A numpy array representing the video frame.
    :return: None
    """
    # Resize the image to a standard size
    image = cv2.resize(image, (720, int(720 * (9 / 16))))

    # Predict the objects in the image using YOLOv8 model
    res = model.predict(image, conf=conf)

    # Plot the detected objects on the video frame
    res_plotted = res[0].plot()
    st_frame.image(res_plotted,
                   caption='Detected Video',
                   channels="BGR",
                   use_column_width=True
                   )

@st.cache_resource
def load_model(model_path):
    """
    Loads a YOLO object detection model from the specified model_path.

    Parameters:
        model_path (str): The path to the YOLO model file.

    Returns:
        A YOLO object detection model.
    """
    model = YOLO(model_path)
    return model

def infer_uploaded_image(conf, model):
    """
    Execute inference for uploaded image
    :param conf: Confidence of YOLOv8 model
    :param model: An instance of the `YOLOv8` class containing the YOLOv8 model.
    :return: None
    """
    source_img = st.sidebar.file_uploader(
        label="Choose an image...",
        type=("jpg", "jpeg", "png", 'bmp', 'webp')
    )

    col1, col2 = st.columns(2)

    with col1:
        if source_img:
            uploaded_image = Image.open(source_img)
            # adding the uploaded image to the page with caption
            st.image(
                image=source_img,
                caption="Uploaded Image",
                use_column_width=True
            )

    if source_img:
        if st.button("Execution"):
            with st.spinner("Running..."):
                res = model.predict(uploaded_image,
                                    conf=conf)
                boxes = res[0].boxes
                res_plotted = res[0].plot()[:, :, ::-1]

                with col2:
                    st.image(res_plotted,
                             caption="Detected Image",
                             use_column_width=True)
                    try:
                        with st.expander("Detection Results"):
                            for box in boxes:
                                st.write(box.xywh)
                    except Exception as ex:
                        st.write("No image is uploaded yet!")
                        st.write(ex)


def infer_uploaded_video(conf, model):
    """
    Execute inference for uploaded video
    :param conf: Confidence of YOLOv8 model
    :param model: An instance of the `YOLOv8` class containing the YOLOv8 model.
    :return: None
    """
    source_video = st.sidebar.file_uploader(
        label="Choose a video..."
    )

    if source_video:
        st.video(source_video)

    if source_video:
        if st.button("Execution"):
            with st.spinner("Running..."):
                try:
                    tfile = tempfile.NamedTemporaryFile()
                    tfile.write(source_video.read())
                    vid_cap = cv2.VideoCapture(
                        tfile.name)
                    st_frame = st.empty()
                    while (vid_cap.isOpened()):
                        success, image = vid_cap.read()
                        if success:
                            _display_detected_frames(conf,
                                                     model,
                                                     st_frame,
                                                     image
                                                     )
                        else:
                            vid_cap.release()
                            break
                except Exception as e:
                    st.error(f"Error loading video: {e}")


def infer_uploaded_webcam(conf, model):
    """
    Execute inference for webcam.
    :param conf: Confidence of YOLOv8 model
    :param model: An instance of the `YOLOv8` class containing the YOLOv8 model.
    :return: None
    """
    try:
        flag = st.button(
            label="Stop running"
        )
        vid_cap = cv2.VideoCapture(0)  # local camera
        st_frame = st.empty()

     #   cap = cv2.VideoCapture(0)
        # è·å–è§†é¢‘å¸§çš„ç»´åº¦
        frame_width = int(vid_cap.get(3))
        frame_height = int(vid_cap.get(4))

        # frame_count = 150  # 5ç§’è§†é¢‘ï¼Œå‡è®¾æ¯ç§’30å¸§
        frame_rate = 30

        frames = []
        # åˆ›å»ºVideoWriterå¯¹è±¡
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out1 = cv2.VideoWriter(r'.\\outputs\\Total\\new.mp4', fourcc, 20.0, (frame_width, frame_height))
        # å¾ªç¯è§†é¢‘å¸§
        save_flag = False  # ä¿å­˜è§†é¢‘çš„æ ‡å¿—
        elapsed_time = 0  # åˆå§‹æ—¶é—´ä¸º0
        target_class_value = 0  # å‡è®¾ç›®æ ‡ç±»åˆ«å€¼ä¸º1
        start_time = time.time()


        while not flag:
            success, frame = vid_cap.read()

            if success:
                _display_detected_frames(
                            conf,
                            model,
                            st_frame,
                            frame
                        )
                frames.append(frame)
                # ä½¿ç”¨yolov8è¿›è¡Œé¢„æµ‹
                results = model(frame)
                # å¯è§†åŒ–ç»“æœ
                annotated_frame = results[0].plot()
                # å°†å¸¦æ³¨é‡Šçš„å¸§å†™å…¥è§†é¢‘æ–‡ä»¶
                out1.write(annotated_frame)
                for r in results:
                    boxes = r.boxes  # Boxes object for bbox outputs
                    if boxes.cls.numel() != 0:
                        # cls_value = boxes.cls.item()
                        # print('clsæ˜¯', cls_value)
                        cls_tensor = boxes.cls
                        cls_list = cls_tensor.cpu().numpy().tolist()
                    else:
                        cls_list = [99999]
                        print('boxes.cls ä¸­æ²¡æœ‰å…ƒç´ ï¼Œæ— æ³•è½¬æ¢ä¸ºæ ‡é‡', cls_list)
                    end_time = time.time()
                    elapsed_time = end_time - start_time
                    print('é—´éš”æ—¶é—´', elapsed_time)
                    if elapsed_time > 10 and save_flag:  # é‡ç½®ä¿å­˜æ ‡å¿—
                        save_flag = False
                    if target_class_value in cls_list and not save_flag:
                        # if target_class_value in cls_list:
                        timestamp = int(time.time())
                        img_name = os.path.join('./outputs/Screenshot',f'{timestamp}.jpg')
                        cv2.imwrite(img_name, frame)
                        print(f'ä¿å­˜å›¾ç‰‡: {img_name}')

                        frame_count = len(frames)
                        print('å¸§æ•°', frame_count)

                        start_frame = max(0, frame_count - frame_rate * 10)  # åˆ¤æ–­èµ·å§‹å¸§

                        end_frame = min(frame_count + frame_rate * 5, len(frames))  # åˆ¤æ–­ç»“æŸå¸§
                        video_name = os.path.join('./outputs/Screenshot' , f'video_{timestamp}.avi')
                        out = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'DIVX'), frame_rate,
                                              (frame.shape[1], frame.shape[0]))
                        for i in range(start_frame, end_frame):
                            out.write(frames[i])
                            print(i)
                        out.release()
                        print(f'ä¿å­˜è§†é¢‘: {video_name}')

                    
                        save_flag = True  # è®¾ç½®ä¿å­˜æ ‡å¿—ä¸º True
                        frames = frames[start_frame:end_frame]
                        start_time = time.time()

            else:
                # æœ€åç»“å°¾ä¸­æ–­è§†é¢‘å¸§å¾ªç¯
                vid_cap.release()
                break
            # success, image = vid_cap.read()
            # if success:
            #     _display_detected_frames(
            #         conf,
            #         model,
            #         st_frame,
            #         image
            #     )
            # else:
            #     vid_cap.release()
            #     break
    except Exception as e:
        st.error(f"Error loading video: {str(e)}")


# ----------------------------------------------------------------------------------------------------'
# app
st.set_page_config(
    page_title="æ™ºæ…§å·¥åœ°æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
    )
st.title('æ™ºæ…§å·¥åœ°ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ')

st.sidebar.header("æ¨¡å‹")
# sidebar
st.sidebar.header("æ¨¡å‹é…ç½®é€‰æ‹©")

# model options
task_type = st.sidebar.selectbox(
    "ä»»åŠ¡ç±»åˆ«é€‰æ‹©",
    ["æ£€æµ‹", "åˆ†å‰²", "å…³é”®ç‚¹",'Outputs'],
)

model_type = None
if task_type == "æ£€æµ‹":
    model_type = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        config.DETECTION_MODEL_LIST
    )
elif task_type == "åˆ†å‰²":
    model_type = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        config.SEGMENT_MODEL_LIST
    )
elif task_type == "å…³é”®ç‚¹":
    model_type = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        config.POSE_MODEL_LIST
    )
elif task_type == "Outputs":
    model_type = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        config.OUTPUTS_MODEL_LIST
    )
else:
    st.error("Currently only 'Detection' function is implemented")

confidence = float(st.sidebar.slider(
    "ç½®ä¿¡åº¦", 30, 100, 50)) / 100

model_path = ""
if model_type:

    if task_type == "æ£€æµ‹":
        model_path = Path(config.DETECTION_MODEL_DIR, str(model_type))
    elif task_type == "åˆ†å‰²":
        model_path = Path(config.SEGMENT_MODEL_DIR, str(model_type))
    elif task_type == "å…³é”®ç‚¹":
        model_path = Path(config.POSE_MODEL_DIR, str(model_type))
    elif task_type == "Outputs":
        model_path = Path(config.OUTPUTS_MODEL_DIR, str(model_type))
else:
    st.error("Please Select Model in Sidebar")

# load pretrained DL model
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"Unable to load model. Please check the specified path: {model_path}")

# image/video options
st.sidebar.header("Image/Video Config")
source_selectbox = st.sidebar.selectbox(
    "é€‰æ‹©æ¥æº",
    config.SOURCES_LIST
)


source_img = None
if source_selectbox == config.SOURCES_LIST[0]: # Image
    infer_uploaded_image(confidence, model)
elif source_selectbox == config.SOURCES_LIST[1]: # Video
    infer_uploaded_video(confidence, model)
elif source_selectbox == config.SOURCES_LIST[2]: # Webcam
    infer_uploaded_webcam(confidence, model)
else:
    st.error("Currently only 'Image' and 'Video' source are implemented")

# st.button('æäº¤ç”³è¿°')